---
layout: post
title: Kubernetes cluster from scratch. Часть 1. Планирование. Предварительная настройка.
tags: kubernetes k8s
---

Данной записью хочу начать серию постов о развертывании кластера kubernetes с нуля (from scratch). На данный момент существует несколько дистрибутивов, облегчающих операцию развертывания кластера. Список доступных установщиков есть [здесь](https://kubernetes.io/docs/setup/pick-right-solution/) и [здесь](https://kubernetes.io/docs/setup/). Но что бы понять как работает кластер, какие компоненты есть и как они взаимодействуют, было решено пройти всю процедуру по шагам самостоятельно, без какой либо сторонней автоматизации.

### Предварительный план постов:
* Часть 1. Планирование. Предварительная настройка. Установка утилит.
* Часть 2. Генерация сертификатов.
* Часть 3. Генерация Kubernetes Config Files.
* Часть 4. Генерация Data Encryption Config и Encryption Key.
* Часть 5. Установка и конфигурирование etcd
* Часть 6. Установка и конфигурирование flannel.
* Часть 7. Установка и конфигурирования master.
* Часть 8. Установка и конфигурирование worker nodes.
* Часть 9. Деплой DNS Add-on'а
* Чать 10. Проверка работоспособности.

В данном цикле описано создание кластера из четырех серверов. Операционная система - Centos 7.
Распределение ролей по серверам:
- `knode01 (10.3.0.201) - master`
- `node01  (10.3.0.201) - worker node 01`
- `node02  (10.3.0.202) - worker node 02`
- `knode04 (10.3.0.223) - etcd`


Каждая роль требует установки следующих компонент:

__Master__
* Kubernetes
  -  API Server
  -  Scheduler
  -  Controller Manager
* Flannel
* iptables

__Worker Nodes__
* Kubernetes
  -  kubelet
  -  kube-proxy
* Flannel daemon
* Docker
* iptables

__etcd__
* собственно сам etcd, который является хранилицем типа ключ-значение.

## Прежде чем перейти к практической части, необходимо подготовить некоторые данные.

`POD_NETWORK=100.64.0.0/16` - подсеть, которая будет использоваться для overlay network. Из нее будут выделяться IP адреса для pod'ов.

`SERVICE_CLUSTER_IP_RANGE="100.65.0.0/24"` - подсеть, которая будет использоваться только для services в kubernetes кластере.

`KUBE_DNS="100.65.0.10"` - адрес сервиса DNS, взят из SERVICE_CLUSTER_IP_RANGE.

`MASTER_IP="10.3.0.201"` - физический IP адрес сервера с master ролями.

`CLUSTER_NAME="dev-kube-cluster"` - имя кластера

`K8S_SERVICE_IP=100.65.0.1` # IP адрес Kubernetes API Service. K8S_SERVICE_IP будет первым IP адресом из подсети SERVICE_IP_RANGE. Первый IP адрес из сети 100.65.0.0/24 будет 100.65.0.1.



# Подготовка серверов.
Нижеописанные действия нужно выполнить на каждом сервере, который будет в кластере.


* Добавляем в файл `/etc/hosts` записи:
```shell
10.3.0.211  node01
10.3.0.202  node02
10.3.0.201  knode01
10.3.0.223  knode04
```


* Файл /etc/resolv.conf:
```shell
# Generated by NetworkManager
nameserver 10.3.0.2
nameserver 10.3.0.4
```


* Отключаем selinux
```shell
# cat /etc/sysconfig/selinux
SELINUX=disabled
```

* Останавливаем и отключаем  firewalld
```shell
# systemctl stop firewalld
# systemctl disable firewalld
```

* Отключаем swap, так как kubelet требует отключенного swap на машине (можно использовать флаг --fail-swap-on для kubelet)
```shell
[root@knode02 cert_nodes]# swapoff -a
```
Нужно закомментировать или удалить строки связанные с типом fs - swap
```shell
[root@knode02 cert_nodes]# vim /etc/fstab 
#/dev/mapper/centos-swap swap                    swap    defaults        0 0 
```

* Устанавливаем docker-ce (официальная документация [тут](https://docs.docker.com/install/linux/docker-ce/centos/))

Если стоит старая версия, ее нужно удалить:
```shell
# yum remove docker \
                  docker-client \
                  docker-client-latest \
                  docker-common \
                  docker-latest \
                  docker-latest-logrotate \
                  docker-logrotate \
                  docker-engine
```

Устанавливаем утилиты:
```shell
# yum install -y yum-utils \
  device-mapper-persistent-data \
  lvm2
```


Добавляем репозиторий:
```shell
# yum-config-manager \
    --add-repo \
    https://download.docker.com/linux/centos/docker-ce.repo
```

Устанавливаем последнюю стабильную версию docker-ce:
```shell
# yum install docker-ce docker-ce-cli containerd.io
```

Запускаем демон и добавляем его в автозагрузку:
```shell
# systemctl start docker
# systemctl enable docker
```

На этом подготоврительные процедуры заверщены. Перезагружаем все сервера для применения изменений.
```shell
# reboot now
```
